{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fine-tuning (Llama-2-7b-chat)\n",
    "for predicting esg risk level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.datacamp.com/tutorial/fine-tuning-llama-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from datasets import Dataset\n",
    "from datetime import datetime\n",
    "from peft import LoraConfig\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(547, 6)\n"
     ]
    }
   ],
   "source": [
    "train_path = \"data/processed/train_esg_shortened.csv\"\n",
    "df_train = pd.read_csv(train_path)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>transcript_esg</th>\n",
       "      <th>esg_score</th>\n",
       "      <th>esg_risk_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>thank emily welcome everyone agilents conferen...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>thank hannah welcome everyone agilents confere...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol  year  quarter                                     transcript_esg  \\\n",
       "0      A  2022        1  thank emily welcome everyone agilents conferen...   \n",
       "1      A  2022        3  thank hannah welcome everyone agilents confere...   \n",
       "2   AAPL  2022        1  good day welcome apple q fy earnings conferenc...   \n",
       "3   AAPL  2022        2  good day welcome apple q fy earnings conferenc...   \n",
       "4   AAPL  2022        3  good day welcome apple q fy earnings conferenc...   \n",
       "\n",
       "   esg_score esg_risk_level  \n",
       "0       15.0            Low  \n",
       "1       15.0            Low  \n",
       "2       17.0            Low  \n",
       "3       17.0            Low  \n",
       "4       17.0            Low  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low' 'Medium' 'Severe' 'High' 'Negligible']\n"
     ]
    }
   ],
   "source": [
    "# check the unique labels in train\n",
    "unique_labels = df_train['esg_risk_level'].unique()\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_esg</th>\n",
       "      <th>esg_risk_level</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank emily welcome everyone agilents conferen...</td>\n",
       "      <td>Low</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an rating agency. Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thank hannah welcome everyone agilents confere...</td>\n",
       "      <td>Low</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an rating agency. Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>Low</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an rating agency. Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>Low</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an rating agency. Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>Low</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an rating agency. Y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      transcript_esg esg_risk_level  \\\n",
       "0  thank emily welcome everyone agilents conferen...            Low   \n",
       "1  thank hannah welcome everyone agilents confere...            Low   \n",
       "2  good day welcome apple q fy earnings conferenc...            Low   \n",
       "3  good day welcome apple q fy earnings conferenc...            Low   \n",
       "4  good day welcome apple q fy earnings conferenc...            Low   \n",
       "\n",
       "                                                text  \n",
       "0  <s>[INST] <<SYS>>\\nYou are an rating agency. Y...  \n",
       "1  <s>[INST] <<SYS>>\\nYou are an rating agency. Y...  \n",
       "2  <s>[INST] <<SYS>>\\nYou are an rating agency. Y...  \n",
       "3  <s>[INST] <<SYS>>\\nYou are an rating agency. Y...  \n",
       "4  <s>[INST] <<SYS>>\\nYou are an rating agency. Y...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_question_answer(transcript_esg, esg_risk_level):\n",
    "    system_msg = \"<<SYS>>\\n\" \\\n",
    "        + \"You are an rating agency. Your task is to predict the a company's ESG Risk Level from a meeting transcript.\" \\\n",
    "        + \"You should evaluate the company's performance on Environmental, Social and Governance issues.\" \\\n",
    "        + \"The possible Risk Levels, from low to high, are `Negligible`, `Low`, `Medium`, `High`, `Severe`.\\n\" \\\n",
    "        + \"<</SYS>>\\n\\n\"\n",
    "    prompt = f\"<s>[INST] {system_msg}###Transcript: {transcript_esg}###Risk Level: [/INST] `{esg_risk_level}`</s>\"\n",
    "    return prompt\n",
    "\n",
    "df_train[\"text\"] = df_train.apply(\n",
    "    lambda row: combine_question_answer(row.transcript_esg, row.esg_risk_level), axis=1\n",
    ")\n",
    "df_train[[\"transcript_esg\", \"esg_risk_level\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>[INST] <<SYS>>\\nYou are an rating agency. Your task is to predict the a company's ESG Risk Level from a meeting transcript.You should evaluate the company's performance on Environmental, Social and Governance issues.The possible Risk Levels, from low to high, are `Negligible`, `Low`, `Medium`, `High`, `Severe`.\\n<</SYS>>\\n\\n###Transcript: thank emily welcome everyone agilents conference call first quarter fiscal year mike mcmullen agilent president ceo bob mcmahon agilent senior vice president cfo joining qa mike bob comment jacob thaysen president agilent life science applied market group sam raha president agilent diagnostics genomics group padraig mcdonnell president agilent crosslab group presentation webcast live change impact company consolidated financial statement also make forwardlooking statement financial performance company statement subject risk uncertainty valid today company assumes obligation update thanks parmeet thanks everyone joining call today momentum continues agilent team delivered strong start q exceeding expectation top bottom line q revenue billion core reported top growing core q year ago excluding covidrelated revenue core growth even better quarter continued see strength order book robust order intake throughout quarter pharma business agilents largest market continues lead way u growing global endmarket demand product service remains strong biopharma grew small molecule growth came robust momentum chemical energy business also continues delivering growth quarter pathology business grew roughly strength across region core genomics business grew low teen strength target enrichment genomics quality control product line nasd team continues deliver driving plus growth quarter meanwhile additional capacity expansion frederick gmp oligo manufacturing facility continues proceed planned bob providing q outlook along detail improved full year guidance pleased q result looking forward another strong quarter year ahead im also confident team ability execute deliver customer shareholder matter challenge thank call today look forward taking question later academia government market flat q business remained resilient despite omicron impact u university delayed inperson learning period following holiday break december reduced lab activity january seen lab activity improve february believe funding environment remains positive food segment declined low single digit strong growth comparison last year america bright spot u growing midteens europe flat china due difficult comparison lunar new year timing closing performance market environmental forensics smallest market agilent overall geographic basis region grew q led america europe quarter took advantage market volatility repurchase million worth share also paid million dividend returning combined total million shareholder balance sheet remains healthy net leverage ratio time given current market condition expect continue aggressive deploying capital represents core growth adjusting expected point impact related covid year year expect reported growth range exchange rate expected negative impact quarter expected contribute point growth closing q guidance nongaap eps expected range versus prior year###Risk Level: [/INST] `Low`</s>\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenizer and base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_seq_len(text):\n",
    "    return len(tokenizer.tokenize(text))\n",
    "\n",
    "get_seq_len(combine_question_answer(\"\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 2) (42, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train_cut = df_train[df_train.text.apply(lambda t: get_seq_len(t) < 1024)]\n",
    "df_train_cut = df_train_cut.sample(frac=1)\n",
    "dataset_train = Dataset.from_pandas(df_train_cut[[\"text\"]][:int(df_train_cut.shape[0]*0.8)])\n",
    "dataset_eval = Dataset.from_pandas(df_train_cut[[\"text\"]][int(df_train_cut.shape[0]*0.8):])\n",
    "print(dataset_train.shape, dataset_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d69ef161d8f4d4f8245ec2075084bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set params for PEFT fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "training_params = TrainingArguments(\n",
    "    output_dir=f\"./results/results_{timestamp}\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps=10,\n",
    "    save_total_limit=5,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88420841f17741dba16553a005fbff6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/164 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917f304af3d34a1492e48f6941778149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_eval,\n",
    "    peft_config=peft_params,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='164' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [164/164 29:32, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.068100</td>\n",
       "      <td>3.912088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.594300</td>\n",
       "      <td>3.641784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.562100</td>\n",
       "      <td>3.436919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.842500</td>\n",
       "      <td>3.300761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.357800</td>\n",
       "      <td>3.202756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.815600</td>\n",
       "      <td>3.167489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.382700</td>\n",
       "      <td>3.141281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.724100</td>\n",
       "      <td>3.120680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.171000</td>\n",
       "      <td>3.112010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.872200</td>\n",
       "      <td>3.096177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.661800</td>\n",
       "      <td>3.083204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.869800</td>\n",
       "      <td>3.072503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.925400</td>\n",
       "      <td>3.062623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.724500</td>\n",
       "      <td>3.063138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.709800</td>\n",
       "      <td>3.050025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.866200</td>\n",
       "      <td>3.042146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=164, training_loss=3.0459093233434165, metrics={'train_runtime': 1779.508, 'train_samples_per_second': 0.184, 'train_steps_per_second': 0.092, 'total_flos': 9622103436115968.0, 'train_loss': 3.0459093233434165, 'epoch': 2.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llama_models/model_240425_1745/tokenizer_config.json',\n",
       " 'llama_models/model_240425_1745/special_tokens_map.json',\n",
       " 'llama_models/model_240425_1745/tokenizer.model',\n",
       " 'llama_models/model_240425_1745/added_tokens.json',\n",
       " 'llama_models/model_240425_1745/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# edited, added \"llama_\" at the beginning\n",
    "\n",
    "trainer.model.save_pretrained(f\"llama_models/model_{timestamp}\")\n",
    "trainer.tokenizer.save_pretrained(f\"llama_models/model_{timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inferencing & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 6)\n"
     ]
    }
   ],
   "source": [
    "test_path = \"data/processed/test_esg_shortened.csv\"\n",
    "df_test = pd.read_csv(test_path)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>transcript_esg</th>\n",
       "      <th>esg_score</th>\n",
       "      <th>esg_risk_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADP</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>call reference nongaap financial measures beli...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADP</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>call reference nongaap financial measures beli...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADSK</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>addition replay call available autodeskcominve...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Negligible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADSK</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>addition replay call available autodeskcominve...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Negligible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADSK</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>addition replay call available autodeskcominve...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Negligible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol  year  quarter                                     transcript_esg  \\\n",
       "0    ADP  2022        1  call reference nongaap financial measures beli...   \n",
       "1    ADP  2022        1  call reference nongaap financial measures beli...   \n",
       "2   ADSK  2022        1  addition replay call available autodeskcominve...   \n",
       "3   ADSK  2022        3  addition replay call available autodeskcominve...   \n",
       "4   ADSK  2022        4  addition replay call available autodeskcominve...   \n",
       "\n",
       "   esg_score esg_risk_level  \n",
       "0       14.0            Low  \n",
       "1       14.0            Low  \n",
       "2       16.0     Negligible  \n",
       "3       16.0     Negligible  \n",
       "4       16.0     Negligible  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_prompt(transcript_esg):\n",
    "    system_msg = \"<<SYS>>\\n\" \\\n",
    "        + \"You are an rating agency. Your task is to predict the a company's ESG Risk Level from a meeting transcript.\" \\\n",
    "        + \"You should evaluate the company's performance on Environmental, Social and Governance issues.\" \\\n",
    "        + \"The possible Risk Levels, from low to high, are `Negligible`, `Low`, `Medium`, `High`, `Severe`.\\n\" \\\n",
    "        + \"<</SYS>>\\n\\n\"\n",
    "    prompt = f\"<s>[INST] {system_msg}###Transcript: {transcript_esg}###Risk Level: [/INST]\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cut[\"prompt\"] = df_train_cut[\"transcript_esg\"].apply(get_question_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"prompt\"] = df_test[\"transcript_esg\"].apply(get_question_prompt)\n",
    "df_test_cut = df_test[df_test.prompt.apply(lambda p: get_seq_len(p) < 1000)]\n",
    "df_test_cut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_new_tokens=8,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "def get_generated_risk_level(generated_text):\n",
    "    output_text = re.split(r\"\\[\\/INST\\]\\s*\", generated_text, maxsplit=1)[1]\n",
    "    output_text = output_text.split(\"`\")\n",
    "    if len(output_text) >= 3:\n",
    "        return output_text[1]\n",
    "    return None\n",
    "\n",
    "def evaluate_and_save_results(pipeline, df, filename):\n",
    "\n",
    "    # get generated text results as the predicted esg risk level\n",
    "    # input to llama2 to generate text\n",
    "    chunk_size = 4\n",
    "    num_chunks = df.shape[0] // chunk_size + int(df.shape[0] % chunk_size > 0)\n",
    "    results = []\n",
    "    with warnings.catch_warnings(category=UserWarning):\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        for i in tqdm(range(num_chunks)):\n",
    "            result = pipeline(df[\"prompt\"].to_list()[i*chunk_size: (i+1)*chunk_size])\n",
    "            results.extend(result)\n",
    "\n",
    "    # extract the answers from generated text\n",
    "    df[\"generatedText\"] = [res[0][\"generated_text\"] for res in results]\n",
    "    df[\"predicted_esg_risk_level\"] = df[\"generatedText\"].apply(get_generated_risk_level)\n",
    "    df.head()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(df['esg_risk_level'], df[\"predicted_esg_risk_level\"])\n",
    "    print(f\"Accuracy for {filename}: {accuracy}\")\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Medium'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo\n",
    "generated_text = pipe(df_test_cut.prompt[0])[0][\"generated_text\"]\n",
    "get_generated_risk_level(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [04:54<00:00,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for data/processed/train_results_240425_1745.csv: 0.4029126213592233\n",
      "Results saved to data/processed/train_results_240425_1745.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = evaluate_and_save_results(pipe, df_train_cut.copy(), f\"data/processed/train_results_{timestamp}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 9/16 [00:51<00:40,  5.84s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 16/16 [01:26<00:00,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for data/processed/test_results_240425_1745.csv: 0.29508196721311475\n",
      "Results saved to data/processed/test_results_240425_1745.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = evaluate_and_save_results(pipe, df_test_cut.copy(), f\"data/processed/test_results_{timestamp}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apai-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
