{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import string\n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/owenwong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/owenwong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/owenwong/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>transcript_esg</th>\n",
       "      <th>esg_score</th>\n",
       "      <th>esg_risk_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Thank you Emily, and welcome everyone to Agile...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>Thank you, Hannah, and welcome, everyone, to A...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Good day, and welcome to the Apple Q1 FY 2022 ...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>Good day, and welcome to the Apple Q2 FY 2022 ...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>Good day, and welcome to the Apple Q3 FY 2022 ...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>WYNN</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Here we are three years in the global pandemic...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>YUM</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Welcome to the Q1 2022 Yum! Brands Earnings co...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>YUM</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>Before we get started, I would like to remind ...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>Thank you, operator. Good morning, everyone, a...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>Thank you. Good morning, everyone, and welcome...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol  year  quarter                                     transcript_esg  \\\n",
       "0        A  2022        1  Thank you Emily, and welcome everyone to Agile...   \n",
       "1        A  2022        3  Thank you, Hannah, and welcome, everyone, to A...   \n",
       "2     AAPL  2022        1  Good day, and welcome to the Apple Q1 FY 2022 ...   \n",
       "3     AAPL  2022        2  Good day, and welcome to the Apple Q2 FY 2022 ...   \n",
       "4     AAPL  2022        3  Good day, and welcome to the Apple Q3 FY 2022 ...   \n",
       "..     ...   ...      ...                                                ...   \n",
       "603   WYNN  2022        4  Here we are three years in the global pandemic...   \n",
       "604    YUM  2022        1  Welcome to the Q1 2022 Yum! Brands Earnings co...   \n",
       "605    YUM  2022        2  Before we get started, I would like to remind ...   \n",
       "606    ZTS  2022        1  Thank you, operator. Good morning, everyone, a...   \n",
       "607    ZTS  2022        2  Thank you. Good morning, everyone, and welcome...   \n",
       "\n",
       "     esg_score esg_risk_level  \n",
       "0         15.0            Low  \n",
       "1         15.0            Low  \n",
       "2         17.0            Low  \n",
       "3         17.0            Low  \n",
       "4         17.0            Low  \n",
       "..         ...            ...  \n",
       "603       26.0            NaN  \n",
       "604       21.0         Medium  \n",
       "605       21.0         Medium  \n",
       "606       18.0            Low  \n",
       "607       18.0            Low  \n",
       "\n",
       "[608 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../../data/processed/train.csv')\n",
    "test = pd.read_csv('../../data/processed/test.csv')\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "962"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['transcript_esg'][1].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lowercase(msg):\n",
    "    '''\n",
    "    aim: change all words to lower case\n",
    "    '''\n",
    "    return msg.lower()\n",
    "\n",
    "\n",
    "def remove_punctuation(msg):\n",
    "    '''\n",
    "    aim: remove all the punctuation from the tweet given\n",
    "    Punctuations are characters other than alphaters and digits.\n",
    "    '''\n",
    "    return msg.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def remove_stopwords(msg):\n",
    "    '''\n",
    "    aim: remove all stopwords in the tweets\n",
    "    '''\n",
    "    word_tokens = word_tokenize(msg)\n",
    "    filtered_tweet = [word for word in word_tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_tweet)\n",
    "\n",
    "def remove_urls(msg):\n",
    "    '''\n",
    "    aim: remove all the urls contained inside the tweets\n",
    "    '''\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', msg, flags=re.MULTILINE)\n",
    "\n",
    "def remove_numbers(msg): \n",
    "    return re.sub(r'\\d+', '', msg) \n",
    "\n",
    "def clean_transcript(msg): \n",
    "    if not isinstance(msg, str): \n",
    "        return \"\"\n",
    "    msg = remove_numbers(msg) \n",
    "    msg = convert_to_lowercase(msg)\n",
    "    msg = remove_urls(msg)\n",
    "    msg = remove_punctuation(msg)\n",
    "    msg = remove_stopwords(msg)\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>transcript_esg</th>\n",
       "      <th>esg_score</th>\n",
       "      <th>esg_risk_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>thank emily welcome everyone agilents conferen...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>thank hannah welcome everyone agilents confere...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol  year  quarter                                     transcript_esg  \\\n",
       "0      A  2022        1  thank emily welcome everyone agilents conferen...   \n",
       "1      A  2022        3  thank hannah welcome everyone agilents confere...   \n",
       "2   AAPL  2022        1  good day welcome apple q fy earnings conferenc...   \n",
       "3   AAPL  2022        2  good day welcome apple q fy earnings conferenc...   \n",
       "4   AAPL  2022        3  good day welcome apple q fy earnings conferenc...   \n",
       "\n",
       "   esg_score esg_risk_level  \n",
       "0       15.0            Low  \n",
       "1       15.0            Low  \n",
       "2       17.0            Low  \n",
       "3       17.0            Low  \n",
       "4       17.0            Low  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['transcript_esg'] = train['transcript_esg'].apply(clean_transcript)\n",
    "test['transcript_esg'] = test['transcript_esg'].apply(clean_transcript)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['transcript_esg'][1].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>transcript_esg</th>\n",
       "      <th>esg_score</th>\n",
       "      <th>esg_risk_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>thank emily welcome everyone agilents conferen...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>thank hannah welcome everyone agilents confere...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>good day welcome apple q fy earnings conferenc...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>WYNN</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>three year global pandemic later wynn la vega ...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>YUM</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>welcome q yum brand earnings conference call n...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>YUM</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>get started would like remind conference call ...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>thank operator good morning everyone welcome z...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>thank good morning everyone welcome zoetis sec...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol  year  quarter                                     transcript_esg  \\\n",
       "0        A  2022        1  thank emily welcome everyone agilents conferen...   \n",
       "1        A  2022        3  thank hannah welcome everyone agilents confere...   \n",
       "2     AAPL  2022        1  good day welcome apple q fy earnings conferenc...   \n",
       "3     AAPL  2022        2  good day welcome apple q fy earnings conferenc...   \n",
       "4     AAPL  2022        3  good day welcome apple q fy earnings conferenc...   \n",
       "..     ...   ...      ...                                                ...   \n",
       "603   WYNN  2022        4  three year global pandemic later wynn la vega ...   \n",
       "604    YUM  2022        1  welcome q yum brand earnings conference call n...   \n",
       "605    YUM  2022        2  get started would like remind conference call ...   \n",
       "606    ZTS  2022        1  thank operator good morning everyone welcome z...   \n",
       "607    ZTS  2022        2  thank good morning everyone welcome zoetis sec...   \n",
       "\n",
       "     esg_score esg_risk_level  \n",
       "0         15.0            Low  \n",
       "1         15.0            Low  \n",
       "2         17.0            Low  \n",
       "3         17.0            Low  \n",
       "4         17.0            Low  \n",
       "..         ...            ...  \n",
       "603       26.0            NaN  \n",
       "604       21.0         Medium  \n",
       "605       21.0         Medium  \n",
       "606       18.0            Low  \n",
       "607       18.0            Low  \n",
       "\n",
       "[608 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatization(tweet):\n",
    "    '''\n",
    "    aim: perform lemmatization on the text\n",
    "    '''\n",
    "    words = nltk.word_tokenize(tweet)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "# Applying stemming and lemmatization to compare the output\n",
    "train['transcript_esg'] = train['transcript_esg'].apply(lemmatization)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=['transcript_esg', 'esg_score'])\n",
    "test = test.dropna(subset=['transcript_esg', 'esg_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Loading the Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('nbroad/ESG-BERT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding ensures all sequences are the same length, truncation cuts off texts longer than BERT's maximum input length, and return_tensors specifies tensor output.\n",
    "\n",
    "def encode_texts(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Encode the datasets\n",
    "train_encodings = encode_texts(train['transcript_esg'].tolist())\n",
    "test_encodings = encode_texts(test['transcript_esg'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset \n",
    "\n",
    "class ESGDataset(Dataset):\n",
    "    def __init__(self, encodings, scores):\n",
    "        self.encodings = encodings\n",
    "        self.scores = scores\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.scores[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scores)\n",
    "\n",
    "train_dataset = ESGDataset(train_encodings, train['esg_score'].tolist())\n",
    "test_dataset = ESGDataset(test_encodings, test['esg_score'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Modify the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained('nbroad/ESG-BERT')  \n",
    "\n",
    "# For regression, we need to remove the classification head that outputs logits for classes\n",
    "# We set it to 1 so it only output 1 single continuous value \n",
    "model.classifier = torch.nn.Linear(model.config.hidden_size, 1)\n",
    "model.num_labels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owenwong/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/38 [00:00<?, ?it/s]/var/folders/sl/y69_mhl94ls89czh2l0g7d640000gn/T/ipykernel_31214/3458303174.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem()})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(3):  # number of epochs\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    # Wrap the train_loader with tqdm for a progress bar\n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# It is a good practice to save a checkpoint at the end of training that includes\n",
    "# the model state, optimizer state, and any other relevant information.\n",
    "model_save_path = \"../../model/trained_ESG_BERT.pth\"  # Define your path here\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "# Wrap the test loader in tqdm for a progress bar\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "progress_bar = tqdm(test_loader, desc=\"Evaluating\", leave=False)\n",
    "with torch.no_grad():\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits.squeeze(-1).cpu().numpy()\n",
    "        predictions.extend(logits)\n",
    "\n",
    "test['predicted_esg_score'] = predictions\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(test['esg_score'], test['predicted_esg_score'])\n",
    "print(f\"Test MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_with_predictions.csv', index=False)\n",
    "print(\"Results saved with predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ESG Score: 20.692307692307693\n",
      "Range of ESG Scores: 27.0\n"
     ]
    }
   ],
   "source": [
    "mean_esg_score = test['esg_score'].mean()\n",
    "min_esg_score = test['esg_score'].min()\n",
    "max_esg_score = test['esg_score'].max()\n",
    "\n",
    "print(\"Mean ESG Score:\", mean_esg_score)\n",
    "print(\"Range of ESG Scores:\", max_esg_score - min_esg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO-DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Currently the MSE is not good(78.X), perhaps can make it better by hyperparameter finetuning (on lr, batch size, num of epoches, optimizer, parameter, regularization, etc. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
